{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11424800,"sourceType":"datasetVersion","datasetId":7155213}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"d50a5701","cell_type":"code","source":"import numpy as np \nimport pandas as pd\nimport os\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nimport torch\nimport time\nimport wandb\nwandb.login(key=\"f659082c2b19bf3ffaaceceb36c1e280541f6b11\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T08:38:37.238660Z","iopub.execute_input":"2025-04-17T08:38:37.238949Z","iopub.status.idle":"2025-04-17T08:38:50.417658Z","shell.execute_reply.started":"2025-04-17T08:38:37.238923Z","shell.execute_reply":"2025-04-17T08:38:50.417074Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33myeshu183\u001b[0m (\u001b[33myeshu183-indian-institute-of-technology-madras\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":1},{"id":"36035d74","cell_type":"code","source":"base_path_train = \"/kaggle/input/naturalist/inaturalist_12K/train\" \ninput_shape = (224,224)\nid2label = {}\nlabel2id = {}\nlabel_list = []\nX = []\ny = []\nfor id,label in enumerate(os.listdir(base_path_train)):\n    # if label[0]==\".\":\n    #     continue\n    id2label[id] = label\n    label2id[label] = id\n    label_list.append(label)\n    label_path = os.path.join(base_path_train,label)\n    for img_path in os.listdir(label_path):\n        # if img_path == \".DS_Store\":\n        #     continue\n        img = np.array(Image.open(os.path.join(label_path,img_path)))\n        img.resize((*input_shape,3))\n        X.append(img)\n        y.append(id)\n    print(f\"id:{id}, Label: {label} done\")\nX = np.array(X).transpose(0, 3, 1, 2)\nX = torch.tensor(X, dtype=torch.float32)\ny = torch.tensor(y, dtype=torch.long)\nprint(X.shape)\nprint(y.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T08:38:50.418937Z","iopub.execute_input":"2025-04-17T08:38:50.419370Z","iopub.status.idle":"2025-04-17T08:42:00.378744Z","shell.execute_reply.started":"2025-04-17T08:38:50.419351Z","shell.execute_reply":"2025-04-17T08:42:00.377978Z"}},"outputs":[{"name":"stdout","text":"id:0, Label: Reptilia done\nid:1, Label: Animalia done\nid:2, Label: Arachnida done\nid:3, Label: Amphibia done\nid:4, Label: Aves done\nid:5, Label: Mollusca done\nid:6, Label: Fungi done\nid:7, Label: Insecta done\nid:8, Label: Plantae done\nid:9, Label: Mammalia done\ntorch.Size([9999, 3, 224, 224])\ntorch.Size([9999])\n","output_type":"stream"}],"execution_count":2},{"id":"a0810d07","cell_type":"code","source":"base_path_test = \"/kaggle/input/naturalist/inaturalist_12K/val\" \ninput_shape = (224,224)\nX_test = []\ny_test = []\nfor id,label in enumerate(os.listdir(base_path_test)):\n    # if label[0]==\".\":\n    #     continue\n    label_path = os.path.join(base_path_test,label)\n    for img_path in os.listdir(label_path):\n        # if img_path == \".DS_Store\":\n        #     continue\n        img = np.array(Image.open(os.path.join(label_path,img_path)))\n        img.resize((*input_shape,3))\n        X_test.append(img)\n        y_test.append(id)\n    print(f\"Test data id:{id}, Label: {label} done\")\nX_test = np.array(X_test).transpose(0, 3, 1, 2)\nX_test = torch.tensor(X_test, dtype=torch.float32)\ny_test = torch.tensor(y_test, dtype=torch.long)\nprint(X_test.shape)\nprint(y_test.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T08:42:00.379724Z","iopub.execute_input":"2025-04-17T08:42:00.379991Z","iopub.status.idle":"2025-04-17T08:42:31.409916Z","shell.execute_reply.started":"2025-04-17T08:42:00.379973Z","shell.execute_reply":"2025-04-17T08:42:31.409085Z"}},"outputs":[{"name":"stdout","text":"Test data id:0, Label: Reptilia done\nTest data id:1, Label: Animalia done\nTest data id:2, Label: Arachnida done\nTest data id:3, Label: Amphibia done\nTest data id:4, Label: Aves done\nTest data id:5, Label: Mollusca done\nTest data id:6, Label: Fungi done\nTest data id:7, Label: Insecta done\nTest data id:8, Label: Plantae done\nTest data id:9, Label: Mammalia done\ntorch.Size([2000, 3, 224, 224])\ntorch.Size([2000])\n","output_type":"stream"}],"execution_count":3},{"id":"f99ee0cb","cell_type":"code","source":"print(id2label)\nprint(label2id)\nprint(label_list)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T08:42:31.411515Z","iopub.execute_input":"2025-04-17T08:42:31.411731Z","iopub.status.idle":"2025-04-17T08:42:31.416550Z","shell.execute_reply.started":"2025-04-17T08:42:31.411713Z","shell.execute_reply":"2025-04-17T08:42:31.415888Z"}},"outputs":[{"name":"stdout","text":"{0: 'Reptilia', 1: 'Animalia', 2: 'Arachnida', 3: 'Amphibia', 4: 'Aves', 5: 'Mollusca', 6: 'Fungi', 7: 'Insecta', 8: 'Plantae', 9: 'Mammalia'}\n{'Reptilia': 0, 'Animalia': 1, 'Arachnida': 2, 'Amphibia': 3, 'Aves': 4, 'Mollusca': 5, 'Fungi': 6, 'Insecta': 7, 'Plantae': 8, 'Mammalia': 9}\n['Reptilia', 'Animalia', 'Arachnida', 'Amphibia', 'Aves', 'Mollusca', 'Fungi', 'Insecta', 'Plantae', 'Mammalia']\n","output_type":"stream"}],"execution_count":4},{"id":"d5b4ebe7","cell_type":"markdown","source":"## Part-A","metadata":{}},{"id":"86f7a388","cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nimport torchvision\nfrom torchvision import datasets, models, transforms\nfrom torchsummary import summary","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T08:42:31.417214Z","iopub.execute_input":"2025-04-17T08:42:31.417436Z","iopub.status.idle":"2025-04-17T08:42:34.323469Z","shell.execute_reply.started":"2025-04-17T08:42:31.417418Z","shell.execute_reply":"2025-04-17T08:42:34.322916Z"}},"outputs":[],"execution_count":5},{"id":"7e0f5da0","cell_type":"code","source":"from torch.utils.data import DataLoader, TensorDataset\nfrom sklearn.model_selection import train_test_split\nX_train,X_val,y_train,y_val = train_test_split(X,y,test_size=0.2,random_state=42)\n#Getting (X,y) pairs\ntrain_data = TensorDataset(X_train, y_train)\nval_data = TensorDataset(X_val, y_val)\ntest_data = TensorDataset(X_test, y_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T08:42:34.324092Z","iopub.execute_input":"2025-04-17T08:42:34.324516Z","iopub.status.idle":"2025-04-17T08:42:37.892643Z","shell.execute_reply.started":"2025-04-17T08:42:34.324498Z","shell.execute_reply":"2025-04-17T08:42:37.891856Z"}},"outputs":[],"execution_count":6},{"id":"38be8cf7-df0a-4270-a9c2-84b6a5dcb026","cell_type":"code","source":"class customCNN(nn.Module):\n    def __init__(self,m=16,k=3,n=256,m_factor=2,n_conv=5,n_fc=2,activation_func=\"ReLU\",batch_norm=True,dropout=0.5):\n        super().__init__()\n        self.k = k # size of filters (kxk)\n        self.n = n # no.of neurons in the dense layer\n        self.m = m # no. of filters\n        self.m_fac = m_factor # filter multiplier\n        self.conv_layers = nn.ModuleList()\n        self.batch_norm = batch_norm\n        self.bn_layers = nn.ModuleList()\n        self.fc_layers = nn.ModuleList()\n        self.dropout = nn.Dropout(dropout)\n        self.n_conv = n_conv\n        self.n_fc = n_fc\n        m = self.m\n        for i in range(self.n_conv):\n            if i==0:\n                self.conv_layers.append(nn.Conv2d(3,int(m),self.k))\n                self.bn_layers.append(nn.BatchNorm2d(int(m)))\n            else:\n                if m*self.m_fac>=1:\n                    self.conv_layers.append(nn.Conv2d(int(m),int(m*self.m_fac),self.k))\n                    self.bn_layers.append(nn.BatchNorm2d(int(m*self.m_fac)))\n                    m = m*self.m_fac\n                else:\n                    self.m_fac = 1\n                    self.conv_layers.append(nn.Conv2d(int(m),int(m*self.m_fac),self.k))\n                    self.bn_layers.append(nn.BatchNorm2d(int(m*self.m_fac)))\n                    m = m*self.m_fac\n        for i in range(self.n_fc):\n            self.fc_layers.append(nn.LazyLinear(self.n))\n            \n        self.maxpool = nn.MaxPool2d(2,2)\n        self.fc1 = nn.LazyLinear(self.n)\n        self.fc2 = nn.Linear(self.n, 10)\n        activations = {\n            \"mish\": nn.Mish(),\n            \"gelu\": nn.GELU(),\n            \"silu\": nn.SiLU(),\n            \"relu\": nn.ReLU()\n        }\n        self.activation = activations.get(activation_func.lower(), nn.ReLU())\n    def forward(self,x):\n        for i in range(self.n_conv):\n            x = self.conv_layers[i](x)\n            if self.batch_norm:\n                x = self.bn_layers[i](x)\n            x = self.activation(x)\n            x = self.maxpool(x)\n        x = torch.flatten(x,1)\n        for i in range(self.n_fc):\n            x = self.fc_layers[i](x)\n            x = self.dropout(x)\n            x = self.activation(x)\n        x = self.fc2(x)\n        # output = F.softmax(x,dim=1)\n        return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T08:42:37.893502Z","iopub.execute_input":"2025-04-17T08:42:37.893989Z","iopub.status.idle":"2025-04-17T08:42:37.905365Z","shell.execute_reply.started":"2025-04-17T08:42:37.893962Z","shell.execute_reply":"2025-04-17T08:42:37.904706Z"}},"outputs":[],"execution_count":7},{"id":"a867aab8","cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"3e02c656","cell_type":"code","source":"from torch.utils.data import Dataset\n\nclass CustomImageDataset(Dataset):\n    def __init__(self, X, y, transform=None):\n        self.X = X\n        self.y = y\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.X)\n\n    def __getitem__(self, idx):\n        img = self.X[idx]\n        label = self.y[idx]\n\n        # Convert tensor image to PIL for applying torchvision transforms\n        img = transforms.ToPILImage()(img)\n\n        if self.transform:\n            img = self.transform(img)\n\n        return img, label","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T08:42:37.906161Z","iopub.execute_input":"2025-04-17T08:42:37.906418Z","iopub.status.idle":"2025-04-17T08:42:37.945264Z","shell.execute_reply.started":"2025-04-17T08:42:37.906397Z","shell.execute_reply":"2025-04-17T08:42:37.944514Z"}},"outputs":[],"execution_count":8},{"id":"d7828127-17dd-478a-b1f6-1c80dde5f049","cell_type":"code","source":"sweep_config = {\n    'method': 'bayes',\n    'metric': {\n        'name': 'val_accuracy',\n        'goal': 'maximize'\n    },\n    'parameters': {\n        'm': {'values': [32, 64]},\n        'm_factor': {'values': [1, 2, 0.5]},\n        'dropout': {'values': [0.2, 0.3]},\n        'activation_func': {'values': ['ReLU', 'GELU', 'SiLU', 'Mish']},\n        'n_fc' : {'values': [1,2]},\n        'n': {'values':[128,256]},\n        'batch_norm': {'values': [True, False]},\n        'batch_size': {'values': [32, 64]},\n        'data_augmentation': {'values': [True, False]}\n    }\n}\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T08:42:37.945983Z","iopub.execute_input":"2025-04-17T08:42:37.946210Z","iopub.status.idle":"2025-04-17T08:42:37.961537Z","shell.execute_reply.started":"2025-04-17T08:42:37.946185Z","shell.execute_reply":"2025-04-17T08:42:37.960894Z"}},"outputs":[],"execution_count":9},{"id":"661f40ec-eaca-4f5e-8230-b33325168c69","cell_type":"code","source":"def train_sweep():\n    wandb.init()\n    config = wandb.config\n\n    run_name = (f\"act_{config.activation_func}_bs_{config.batch_size}_m_{config.m}_n_{config.n}_nfc_{config.n_fc}\"\n                f\"_mf_{config.m_factor}_do_{config.dropout}_bn_{config.batch_norm}_aug_{config.data_augmentation}\")\n    wandb.run.name = run_name\n\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    model = customCNN(\n        m=config.m,\n        m_factor=config.m_factor,\n        n_fc=config.n_fc,\n        activation_func=config.activation_func,\n        batch_norm=config.batch_norm,\n        dropout=config.dropout\n    ).to(device)\n\n    # Define transforms\n    transform_train = transforms.Compose([\n        transforms.RandomHorizontalFlip(),\n        transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),  # Keeps size while augmenting\n        transforms.ToTensor()\n    ]) if config.data_augmentation else transforms.Compose([\n        transforms.Resize((224, 224)),  # Ensures all images are same size\n        transforms.ToTensor()\n    ])\n    \n    transform_val = transforms.Compose([\n        transforms.Resize((224, 224)),\n        transforms.ToTensor()\n    ])\n\n\n    # Use transformed datasets\n    train_dataset = CustomImageDataset(X_train, y_train, transform=transform_train)\n    val_dataset = CustomImageDataset(X_val, y_val, transform=transform_val)\n    #test_dataset = CustomImageDataset(X_test, y_test, transform=transform_val)\n\n    train_loader = DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True)\n    val_loader = DataLoader(val_dataset, batch_size=config.batch_size, shuffle=False)\n    #test_loader = DataLoader(test_dataset, batch_size=config.batch_size, shuffle=False)\n\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n\n    for epoch in range(5):\n        epoch_start_time = time.time()\n        model.train()\n        running_loss, correct, total = 0, 0, 0\n\n        for inputs, labels in train_loader:\n            inputs, labels = inputs.to(device), labels.to(device)\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n            running_loss += loss.item()\n            _, predicted = torch.max(outputs.data, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n\n        train_loss = running_loss / len(train_loader)\n        train_acc = 100 * correct / total\n\n        # Validation\n        model.eval()\n        val_loss, val_correct, val_total = 0, 0, 0\n        with torch.no_grad():\n            for inputs, labels in val_loader:\n                inputs, labels = inputs.to(device), labels.to(device)\n                outputs = model(inputs)\n                loss = criterion(outputs, labels)\n                val_loss += loss.item()\n                _, predicted = torch.max(outputs.data, 1)\n                val_total += labels.size(0)\n                val_correct += (predicted == labels).sum().item()\n\n        val_loss /= len(val_loader)\n        val_acc = 100 * val_correct / val_total\n\n        epoch_time = time.time() - epoch_start_time\n\n        wandb.log({\n            'train_loss': train_loss,\n            'train_accuracy': train_acc,\n            'val_loss': val_loss,\n            'val_accuracy': val_acc,\n            'epoch_time': epoch_time\n        })\n\n        print(f\"Epoch {epoch+1} | Time: {epoch_time:.2f}s | \"\n              f\"Train Loss: {train_loss:.3f}, Train Acc: {train_acc:.2f}% | \"\n              f\"Val Loss: {val_loss:.3f}, Val Acc: {val_acc:.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T08:42:37.963710Z","iopub.execute_input":"2025-04-17T08:42:37.963969Z","iopub.status.idle":"2025-04-17T08:42:37.978407Z","shell.execute_reply.started":"2025-04-17T08:42:37.963948Z","shell.execute_reply":"2025-04-17T08:42:37.977840Z"}},"outputs":[],"execution_count":10},{"id":"46b1e3fd-2557-4653-8ca5-cc1b90757ac1","cell_type":"code","source":"wandb.finish()\nsweep_id = wandb.sweep(sweep_config, project=\"DA6401_Assignment_02\")\nwandb.agent(sweep_id, function=train_sweep, count=50)  # Runs 50 experiments","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T08:42:37.979048Z","iopub.execute_input":"2025-04-17T08:42:37.979285Z"}},"outputs":[{"name":"stdout","text":"Create sweep with ID: 7rn82ov2\nSweep URL: https://wandb.ai/yeshu183-indian-institute-of-technology-madras/DA6401_Assignment_02/sweeps/7rn82ov2\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: o0f1wfgj with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_func: GELU\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_norm: True\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_augmentation: True\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tm: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tm_factor: 0.5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tn: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tn_fc: 1\n\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250417_084246-o0f1wfgj</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/yeshu183-indian-institute-of-technology-madras/DA6401_Assignment_02/runs/o0f1wfgj' target=\"_blank\">misunderstood-sweep-1</a></strong> to <a href='https://wandb.ai/yeshu183-indian-institute-of-technology-madras/DA6401_Assignment_02' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/yeshu183-indian-institute-of-technology-madras/DA6401_Assignment_02/sweeps/7rn82ov2' target=\"_blank\">https://wandb.ai/yeshu183-indian-institute-of-technology-madras/DA6401_Assignment_02/sweeps/7rn82ov2</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/yeshu183-indian-institute-of-technology-madras/DA6401_Assignment_02' target=\"_blank\">https://wandb.ai/yeshu183-indian-institute-of-technology-madras/DA6401_Assignment_02</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/yeshu183-indian-institute-of-technology-madras/DA6401_Assignment_02/sweeps/7rn82ov2' target=\"_blank\">https://wandb.ai/yeshu183-indian-institute-of-technology-madras/DA6401_Assignment_02/sweeps/7rn82ov2</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/yeshu183-indian-institute-of-technology-madras/DA6401_Assignment_02/runs/o0f1wfgj' target=\"_blank\">https://wandb.ai/yeshu183-indian-institute-of-technology-madras/DA6401_Assignment_02/runs/o0f1wfgj</a>"},"metadata":{}},{"name":"stdout","text":"Epoch 1 | Time: 30.93s | Train Loss: 2.251, Train Acc: 15.10% | Val Loss: 2.210, Val Acc: 18.95%\nEpoch 2 | Time: 29.66s | Train Loss: 2.200, Train Acc: 18.64% | Val Loss: 2.207, Val Acc: 17.85%\nEpoch 3 | Time: 29.67s | Train Loss: 2.188, Train Acc: 18.43% | Val Loss: 2.235, Val Acc: 17.50%\nEpoch 4 | Time: 30.07s | Train Loss: 2.172, Train Acc: 19.28% | Val Loss: 2.186, Val Acc: 20.20%\nEpoch 5 | Time: 30.54s | Train Loss: 2.161, Train Acc: 20.07% | Val Loss: 2.170, Val Acc: 19.95%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch_time</td><td>█▁▁▃▆</td></tr><tr><td>train_accuracy</td><td>▁▆▆▇█</td></tr><tr><td>train_loss</td><td>█▄▃▂▁</td></tr><tr><td>val_accuracy</td><td>▅▂▁█▇</td></tr><tr><td>val_loss</td><td>▅▅█▃▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch_time</td><td>30.54307</td></tr><tr><td>train_accuracy</td><td>20.06501</td></tr><tr><td>train_loss</td><td>2.16145</td></tr><tr><td>val_accuracy</td><td>19.95</td></tr><tr><td>val_loss</td><td>2.17035</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">act_GELU_bs_64_m_64_n_256_nfc_1_mf_0.5_do_0.2_bn_True_aug_True</strong> at: <a href='https://wandb.ai/yeshu183-indian-institute-of-technology-madras/DA6401_Assignment_02/runs/o0f1wfgj' target=\"_blank\">https://wandb.ai/yeshu183-indian-institute-of-technology-madras/DA6401_Assignment_02/runs/o0f1wfgj</a><br> View project at: <a href='https://wandb.ai/yeshu183-indian-institute-of-technology-madras/DA6401_Assignment_02' target=\"_blank\">https://wandb.ai/yeshu183-indian-institute-of-technology-madras/DA6401_Assignment_02</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250417_084246-o0f1wfgj/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: qecksstq with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_func: ReLU\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_norm: True\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_augmentation: False\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tm: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tm_factor: 1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tn: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tn_fc: 1\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250417_084537-qecksstq</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/yeshu183-indian-institute-of-technology-madras/DA6401_Assignment_02/runs/qecksstq' target=\"_blank\">fallen-sweep-2</a></strong> to <a href='https://wandb.ai/yeshu183-indian-institute-of-technology-madras/DA6401_Assignment_02' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/yeshu183-indian-institute-of-technology-madras/DA6401_Assignment_02/sweeps/7rn82ov2' target=\"_blank\">https://wandb.ai/yeshu183-indian-institute-of-technology-madras/DA6401_Assignment_02/sweeps/7rn82ov2</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/yeshu183-indian-institute-of-technology-madras/DA6401_Assignment_02' target=\"_blank\">https://wandb.ai/yeshu183-indian-institute-of-technology-madras/DA6401_Assignment_02</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/yeshu183-indian-institute-of-technology-madras/DA6401_Assignment_02/sweeps/7rn82ov2' target=\"_blank\">https://wandb.ai/yeshu183-indian-institute-of-technology-madras/DA6401_Assignment_02/sweeps/7rn82ov2</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/yeshu183-indian-institute-of-technology-madras/DA6401_Assignment_02/runs/qecksstq' target=\"_blank\">https://wandb.ai/yeshu183-indian-institute-of-technology-madras/DA6401_Assignment_02/runs/qecksstq</a>"},"metadata":{}},{"name":"stdout","text":"Epoch 1 | Time: 22.45s | Train Loss: 2.256, Train Acc: 16.10% | Val Loss: 2.240, Val Acc: 17.35%\nEpoch 2 | Time: 22.61s | Train Loss: 2.223, Train Acc: 17.14% | Val Loss: 2.200, Val Acc: 19.45%\nEpoch 3 | Time: 22.53s | Train Loss: 2.214, Train Acc: 17.99% | Val Loss: 2.258, Val Acc: 17.50%\nEpoch 4 | Time: 22.34s | Train Loss: 2.200, Train Acc: 18.03% | Val Loss: 2.218, Val Acc: 17.60%\nEpoch 5 | Time: 22.95s | Train Loss: 2.202, Train Acc: 18.66% | Val Loss: 2.241, Val Acc: 19.65%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch_time</td><td>▂▄▃▁█</td></tr><tr><td>train_accuracy</td><td>▁▄▆▆█</td></tr><tr><td>train_loss</td><td>█▄▃▁▁</td></tr><tr><td>val_accuracy</td><td>▁▇▁▂█</td></tr><tr><td>val_loss</td><td>▆▁█▃▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch_time</td><td>22.95325</td></tr><tr><td>train_accuracy</td><td>18.66483</td></tr><tr><td>train_loss</td><td>2.20193</td></tr><tr><td>val_accuracy</td><td>19.65</td></tr><tr><td>val_loss</td><td>2.24056</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">act_ReLU_bs_32_m_64_n_128_nfc_1_mf_1_do_0.3_bn_True_aug_False</strong> at: <a href='https://wandb.ai/yeshu183-indian-institute-of-technology-madras/DA6401_Assignment_02/runs/qecksstq' target=\"_blank\">https://wandb.ai/yeshu183-indian-institute-of-technology-madras/DA6401_Assignment_02/runs/qecksstq</a><br> View project at: <a href='https://wandb.ai/yeshu183-indian-institute-of-technology-madras/DA6401_Assignment_02' target=\"_blank\">https://wandb.ai/yeshu183-indian-institute-of-technology-madras/DA6401_Assignment_02</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250417_084537-qecksstq/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ze7wlhfo with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_func: SiLU\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_norm: False\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_augmentation: True\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tm: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tm_factor: 2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tn: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tn_fc: 1\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250417_084749-ze7wlhfo</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/yeshu183-indian-institute-of-technology-madras/DA6401_Assignment_02/runs/ze7wlhfo' target=\"_blank\">iconic-sweep-3</a></strong> to <a href='https://wandb.ai/yeshu183-indian-institute-of-technology-madras/DA6401_Assignment_02' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/yeshu183-indian-institute-of-technology-madras/DA6401_Assignment_02/sweeps/7rn82ov2' target=\"_blank\">https://wandb.ai/yeshu183-indian-institute-of-technology-madras/DA6401_Assignment_02/sweeps/7rn82ov2</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/yeshu183-indian-institute-of-technology-madras/DA6401_Assignment_02' target=\"_blank\">https://wandb.ai/yeshu183-indian-institute-of-technology-madras/DA6401_Assignment_02</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/yeshu183-indian-institute-of-technology-madras/DA6401_Assignment_02/sweeps/7rn82ov2' target=\"_blank\">https://wandb.ai/yeshu183-indian-institute-of-technology-madras/DA6401_Assignment_02/sweeps/7rn82ov2</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/yeshu183-indian-institute-of-technology-madras/DA6401_Assignment_02/runs/ze7wlhfo' target=\"_blank\">https://wandb.ai/yeshu183-indian-institute-of-technology-madras/DA6401_Assignment_02/runs/ze7wlhfo</a>"},"metadata":{}},{"name":"stdout","text":"Epoch 1 | Time: 24.55s | Train Loss: 2.296, Train Acc: 12.26% | Val Loss: 2.309, Val Acc: 13.65%\nEpoch 2 | Time: 24.27s | Train Loss: 2.261, Train Acc: 14.71% | Val Loss: 2.263, Val Acc: 18.85%\nEpoch 3 | Time: 24.50s | Train Loss: 2.244, Train Acc: 15.81% | Val Loss: 2.227, Val Acc: 17.35%\nEpoch 4 | Time: 24.55s | Train Loss: 2.238, Train Acc: 15.96% | Val Loss: 2.232, Val Acc: 18.55%\nEpoch 5 | Time: 24.42s | Train Loss: 2.217, Train Acc: 18.29% | Val Loss: 2.249, Val Acc: 18.00%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch_time</td><td>█▁▇█▅</td></tr><tr><td>train_accuracy</td><td>▁▄▅▅█</td></tr><tr><td>train_loss</td><td>█▅▃▃▁</td></tr><tr><td>val_accuracy</td><td>▁█▆█▇</td></tr><tr><td>val_loss</td><td>█▄▁▁▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch_time</td><td>24.42059</td></tr><tr><td>train_accuracy</td><td>18.28979</td></tr><tr><td>train_loss</td><td>2.2171</td></tr><tr><td>val_accuracy</td><td>18</td></tr><tr><td>val_loss</td><td>2.24898</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">act_SiLU_bs_32_m_32_n_128_nfc_1_mf_2_do_0.2_bn_False_aug_True</strong> at: <a href='https://wandb.ai/yeshu183-indian-institute-of-technology-madras/DA6401_Assignment_02/runs/ze7wlhfo' target=\"_blank\">https://wandb.ai/yeshu183-indian-institute-of-technology-madras/DA6401_Assignment_02/runs/ze7wlhfo</a><br> View project at: <a href='https://wandb.ai/yeshu183-indian-institute-of-technology-madras/DA6401_Assignment_02' target=\"_blank\">https://wandb.ai/yeshu183-indian-institute-of-technology-madras/DA6401_Assignment_02</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250417_084749-ze7wlhfo/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: nhl6x2wd with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_func: ReLU\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_norm: True\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_augmentation: False\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tm: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tm_factor: 1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tn: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tn_fc: 2\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250417_085017-nhl6x2wd</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/yeshu183-indian-institute-of-technology-madras/DA6401_Assignment_02/runs/nhl6x2wd' target=\"_blank\">fast-sweep-4</a></strong> to <a href='https://wandb.ai/yeshu183-indian-institute-of-technology-madras/DA6401_Assignment_02' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/yeshu183-indian-institute-of-technology-madras/DA6401_Assignment_02/sweeps/7rn82ov2' target=\"_blank\">https://wandb.ai/yeshu183-indian-institute-of-technology-madras/DA6401_Assignment_02/sweeps/7rn82ov2</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/yeshu183-indian-institute-of-technology-madras/DA6401_Assignment_02' target=\"_blank\">https://wandb.ai/yeshu183-indian-institute-of-technology-madras/DA6401_Assignment_02</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/yeshu183-indian-institute-of-technology-madras/DA6401_Assignment_02/sweeps/7rn82ov2' target=\"_blank\">https://wandb.ai/yeshu183-indian-institute-of-technology-madras/DA6401_Assignment_02/sweeps/7rn82ov2</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/yeshu183-indian-institute-of-technology-madras/DA6401_Assignment_02/runs/nhl6x2wd' target=\"_blank\">https://wandb.ai/yeshu183-indian-institute-of-technology-madras/DA6401_Assignment_02/runs/nhl6x2wd</a>"},"metadata":{}},{"name":"stdout","text":"Epoch 1 | Time: 25.06s | Train Loss: 2.245, Train Acc: 16.06% | Val Loss: 2.199, Val Acc: 18.70%\nEpoch 2 | Time: 25.03s | Train Loss: 2.203, Train Acc: 18.05% | Val Loss: 2.196, Val Acc: 17.50%\n","output_type":"stream"}],"execution_count":null},{"id":"c5720713-9071-4e77-a01e-83d53ba5b1da","cell_type":"code","source":"from types import SimpleNamespace\ndef train_best_model(best_config,n_epochs=20):\n    config = SimpleNamespace(**best_config)\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    model = customCNN(\n        m=config.m,\n        m_factor=config.m_factor,\n        n_fc=config.n_fc,\n        activation_func=config.activation_func,\n        batch_norm=config.batch_norm,\n        dropout=config.dropout\n    ).to(device)\n\n    # Define transforms\n    transform_train = transforms.Compose([\n        transforms.RandomHorizontalFlip(),\n        transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),  # Keeps size while augmenting\n        transforms.ToTensor()\n    ]) if config.data_augmentation else transforms.Compose([\n        transforms.Resize((224, 224)),  # Ensures all images are same size\n        transforms.ToTensor()\n    ])\n    \n    transform_val = transforms.Compose([\n        transforms.Resize((224, 224)),\n        transforms.ToTensor()\n    ])\n\n    # Use transformed datasets\n    train_dataset = CustomImageDataset(X_train, y_train, transform=transform_train)\n    val_dataset = CustomImageDataset(X_val, y_val, transform=transform_val)\n    #test_dataset = CustomImageDataset(X_test, y_test, transform=transform_val)\n\n    train_loader = DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True)\n    val_loader = DataLoader(val_dataset, batch_size=config.batch_size, shuffle=False)\n    #test_loader = DataLoader(test_dataset, batch_size=config.batch_size, shuffle=False)\n\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n\n    for epoch in range(5):\n        epoch_start_time = time.time()\n        model.train()\n        running_loss, correct, total = 0, 0, 0\n\n        for inputs, labels in train_loader:\n            inputs, labels = inputs.to(device), labels.to(device)\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n            running_loss += loss.item()\n            _, predicted = torch.max(outputs.data, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n\n        train_loss = running_loss / len(train_loader)\n        train_acc = 100 * correct / total\n\n        # Validation\n        model.eval()\n        val_loss, val_correct, val_total = 0, 0, 0\n        with torch.no_grad():\n            for inputs, labels in val_loader:\n                inputs, labels = inputs.to(device), labels.to(device)\n                outputs = model(inputs)\n                loss = criterion(outputs, labels)\n                val_loss += loss.item()\n                _, predicted = torch.max(outputs.data, 1)\n                val_total += labels.size(0)\n                val_correct += (predicted == labels).sum().item()\n\n        val_loss /= len(val_loader)\n        val_acc = 100 * val_correct / val_total\n\n        epoch_time = time.time() - epoch_start_time\n\n        wandb.log({\n            'train_loss': train_loss,\n            'train_accuracy': train_acc,\n            'val_loss': val_loss,\n            'val_accuracy': val_acc,\n            'epoch_time': epoch_time\n        })\n\n        print(f\"Epoch {epoch+1} | Time: {epoch_time:.2f}s | \"\n              f\"Train Loss: {train_loss:.3f}, Train Acc: {train_acc:.2f}% | \"\n              f\"Val Loss: {val_loss:.3f}, Val Acc: {val_acc:.2f}%\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"a0834798-55e3-44c8-a6eb-5d62cf4438f5","cell_type":"code","source":"api = wandb.Api()\n\nsweep_path = \"DA6401_Assignment_02/7rn82ov2\"\nruns = api.runs(sweep_path)\n\nsorted_runs = sorted(runs, key=lambda run: run.summary.get(\"val_accuracy\", 0), reverse=True)\n\nbest_run = sorted_runs[0]\nbest_config = {}\nprint(len(sorted_runs))\nprint(\"Best Run Name:\", best_run.name)\nprint(\"Best Val Accuracy:\", best_run.summary[\"val_accuracy\"])\nprint(\"Best Hyperparameters:\")\nfor k, v in best_run.config.items():\n    best_config[k] = v\nprint(best_config)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"a8c1b083-ebf6-4292-98d9-c6cbd24cf48a","cell_type":"code","source":"model = train_best_model(best_config,n_epochs=30)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"9ef3290a-395e-415e-99db-b9c24484b370","cell_type":"code","source":"transform_test = transforms.Compose([\n        transforms.Resize((224, 224)),\n        transforms.ToTensor()\n    ])\ntest_dataset = CustomImageDataset(X_test, y_test, transform=transform_test)\ntest_loader = DataLoader(test_dataset, batch_size=config.batch_size, shuffle=False)\nmodel.eval()\ntest_loss, test_correct, test_total = 0, 0, 0\nall_preds = []\nall_imgs = []\n\nwith torch.no_grad():\n    for inputs, labels in test_loader:\n        inputs, labels = inputs.to(device), labels.to(device)\n        outputs = model(inputs)\n        _, predicted = torch.max(outputs, 1)\n        test_total += labels.size(0)\n        test_correct += (predicted == labels).sum().item()\n\n        all_preds.extend(predicted.cpu())\n        all_imgs.extend(inputs.cpu())\n\ntest_accuracy = 100 * test_correct / test_total\nprint(f\" Final Test Accuracy: {test_accuracy:.2f}%\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"627b67c5-797e-4b78-99a7-f6a431b381f2","cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"89ef2ef4-687f-4bb0-8c29-487940a198a1","cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"63b07037-a451-42d1-9b8a-e35305035e7e","cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"e9bc2b17","cell_type":"code","source":"# import matplotlib.pyplot as plt\n\n# epochs = range(1, len(train_losses) + 1)\n\n# # Plot Loss\n# plt.figure(figsize=(12, 5))\n# plt.subplot(1, 2, 1)\n# plt.plot(epochs, train_losses, label='Train Loss', marker='o')\n# plt.plot(epochs, val_losses, label='Validation Loss', marker='o')\n# plt.title('Loss over Epochs')\n# plt.xlabel('Epoch')\n# plt.ylabel('Loss')\n# plt.legend()\n# plt.grid(True)\n\n# # Plot Accuracy\n# plt.subplot(1, 2, 2)\n# plt.plot(epochs, train_accuracies, label='Train Accuracy', marker='o')\n# plt.plot(epochs, val_accuracies, label='Validation Accuracy', marker='o')\n# plt.title('Accuracy over Epochs')\n# plt.xlabel('Epoch')\n# plt.ylabel('Accuracy (%)')\n# plt.legend()\n# plt.grid(True)\n\n# plt.tight_layout()\n# plt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"eabe2870-29ff-48ce-acc7-d32716cf6479","cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}